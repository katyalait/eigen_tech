<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=emulateIE7" />
    <title>Coverage for /home/kate/.local/lib/python3.6/site-packages/sklearn/linear_model/sag.py: 12%</title>
    <link rel="stylesheet" href="style.css" type="text/css">
    <script type="text/javascript" src="jquery.min.js"></script>
    <script type="text/javascript" src="jquery.hotkeys.js"></script>
    <script type="text/javascript" src="jquery.isonscreen.js"></script>
    <script type="text/javascript" src="coverage_html.js"></script>
    <script type="text/javascript">
        jQuery(document).ready(coverage.pyfile_ready);
    </script>
</head>
<body class="pyfile">
<div id="header">
    <div class="content">
        <h1>Coverage for <b>/home/kate/.local/lib/python3.6/site-packages/sklearn/linear_model/sag.py</b> :
            <span class="pc_cov">12%</span>
        </h1>
        <img id="keyboard_icon" src="keybd_closed.png" alt="Show keyboard shortcuts" />
        <h2 class="stats">
            73 statements &nbsp;
            <span class="run shortkey_r button_toggle_run">9 run</span>
            <span class="mis show_mis shortkey_m button_toggle_mis">64 missing</span>
            <span class="exc show_exc shortkey_x button_toggle_exc">0 excluded</span>
        </h2>
    </div>
</div>
<div class="help_panel">
    <img id="panel_icon" src="keybd_open.png" alt="Hide keyboard shortcuts" />
    <p class="legend">Hot-keys on this page</p>
    <div>
    <p class="keyhelp">
        <span class="key">r</span>
        <span class="key">m</span>
        <span class="key">x</span>
        <span class="key">p</span> &nbsp; toggle line displays
    </p>
    <p class="keyhelp">
        <span class="key">j</span>
        <span class="key">k</span> &nbsp; next/prev highlighted chunk
    </p>
    <p class="keyhelp">
        <span class="key">0</span> &nbsp; (zero) top of page
    </p>
    <p class="keyhelp">
        <span class="key">1</span> &nbsp; (one) first highlighted chunk
    </p>
    </div>
</div>
<div id="source">
    <p id="t1" class="pln"><span class="n"><a href="#t1">1</a></span><span class="t"><span class="str">"""Solvers for Ridge and LogisticRegression using SAG algorithm"""</span>&nbsp;</span><span class="r"></span></p>
    <p id="t2" class="pln"><span class="n"><a href="#t2">2</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t3" class="pln"><span class="n"><a href="#t3">3</a></span><span class="t"><span class="com"># Authors: Tom Dupre la Tour &lt;tom.dupre-la-tour@m4x.org></span>&nbsp;</span><span class="r"></span></p>
    <p id="t4" class="pln"><span class="n"><a href="#t4">4</a></span><span class="t"><span class="com">#</span>&nbsp;</span><span class="r"></span></p>
    <p id="t5" class="pln"><span class="n"><a href="#t5">5</a></span><span class="t"><span class="com"># License: BSD 3 clause</span>&nbsp;</span><span class="r"></span></p>
    <p id="t6" class="pln"><span class="n"><a href="#t6">6</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t7" class="run"><span class="n"><a href="#t7">7</a></span><span class="t"><span class="key">import</span> <span class="nam">warnings</span>&nbsp;</span><span class="r"></span></p>
    <p id="t8" class="pln"><span class="n"><a href="#t8">8</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t9" class="run"><span class="n"><a href="#t9">9</a></span><span class="t"><span class="key">import</span> <span class="nam">numpy</span> <span class="key">as</span> <span class="nam">np</span>&nbsp;</span><span class="r"></span></p>
    <p id="t10" class="pln"><span class="n"><a href="#t10">10</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t11" class="run"><span class="n"><a href="#t11">11</a></span><span class="t"><span class="key">from</span> <span class="op">.</span><span class="nam">base</span> <span class="key">import</span> <span class="nam">make_dataset</span>&nbsp;</span><span class="r"></span></p>
    <p id="t12" class="run"><span class="n"><a href="#t12">12</a></span><span class="t"><span class="key">from</span> <span class="op">.</span><span class="nam">sag_fast</span> <span class="key">import</span> <span class="nam">sag32</span><span class="op">,</span> <span class="nam">sag64</span>&nbsp;</span><span class="r"></span></p>
    <p id="t13" class="run"><span class="n"><a href="#t13">13</a></span><span class="t"><span class="key">from</span> <span class="op">.</span><span class="op">.</span><span class="nam">exceptions</span> <span class="key">import</span> <span class="nam">ConvergenceWarning</span>&nbsp;</span><span class="r"></span></p>
    <p id="t14" class="run"><span class="n"><a href="#t14">14</a></span><span class="t"><span class="key">from</span> <span class="op">.</span><span class="op">.</span><span class="nam">utils</span> <span class="key">import</span> <span class="nam">check_array</span>&nbsp;</span><span class="r"></span></p>
    <p id="t15" class="run"><span class="n"><a href="#t15">15</a></span><span class="t"><span class="key">from</span> <span class="op">.</span><span class="op">.</span><span class="nam">utils</span><span class="op">.</span><span class="nam">extmath</span> <span class="key">import</span> <span class="nam">row_norms</span>&nbsp;</span><span class="r"></span></p>
    <p id="t16" class="pln"><span class="n"><a href="#t16">16</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t17" class="pln"><span class="n"><a href="#t17">17</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t18" class="run"><span class="n"><a href="#t18">18</a></span><span class="t"><span class="key">def</span> <span class="nam">get_auto_step_size</span><span class="op">(</span><span class="nam">max_squared_sum</span><span class="op">,</span> <span class="nam">alpha_scaled</span><span class="op">,</span> <span class="nam">loss</span><span class="op">,</span> <span class="nam">fit_intercept</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t19" class="pln"><span class="n"><a href="#t19">19</a></span><span class="t">                       <span class="nam">n_samples</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t20" class="pln"><span class="n"><a href="#t20">20</a></span><span class="t">                       <span class="nam">is_saga</span><span class="op">=</span><span class="key">False</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t21" class="pln"><span class="n"><a href="#t21">21</a></span><span class="t">    <span class="str">"""Compute automatic step size for SAG solver</span>&nbsp;</span><span class="r"></span></p>
    <p id="t22" class="pln"><span class="n"><a href="#t22">22</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t23" class="pln"><span class="n"><a href="#t23">23</a></span><span class="t"><span class="str">    The step size is set to 1 / (alpha_scaled + L + fit_intercept) where L is</span>&nbsp;</span><span class="r"></span></p>
    <p id="t24" class="pln"><span class="n"><a href="#t24">24</a></span><span class="t"><span class="str">    the max sum of squares for over all samples.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t25" class="pln"><span class="n"><a href="#t25">25</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t26" class="pln"><span class="n"><a href="#t26">26</a></span><span class="t"><span class="str">    Parameters</span>&nbsp;</span><span class="r"></span></p>
    <p id="t27" class="pln"><span class="n"><a href="#t27">27</a></span><span class="t"><span class="str">    ----------</span>&nbsp;</span><span class="r"></span></p>
    <p id="t28" class="pln"><span class="n"><a href="#t28">28</a></span><span class="t"><span class="str">    max_squared_sum : float</span>&nbsp;</span><span class="r"></span></p>
    <p id="t29" class="pln"><span class="n"><a href="#t29">29</a></span><span class="t"><span class="str">        Maximum squared sum of X over samples.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t30" class="pln"><span class="n"><a href="#t30">30</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t31" class="pln"><span class="n"><a href="#t31">31</a></span><span class="t"><span class="str">    alpha_scaled : float</span>&nbsp;</span><span class="r"></span></p>
    <p id="t32" class="pln"><span class="n"><a href="#t32">32</a></span><span class="t"><span class="str">        Constant that multiplies the regularization term, scaled by</span>&nbsp;</span><span class="r"></span></p>
    <p id="t33" class="pln"><span class="n"><a href="#t33">33</a></span><span class="t"><span class="str">        1. / n_samples, the number of samples.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t34" class="pln"><span class="n"><a href="#t34">34</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t35" class="pln"><span class="n"><a href="#t35">35</a></span><span class="t"><span class="str">    loss : string, in {"log", "squared"}</span>&nbsp;</span><span class="r"></span></p>
    <p id="t36" class="pln"><span class="n"><a href="#t36">36</a></span><span class="t"><span class="str">        The loss function used in SAG solver.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t37" class="pln"><span class="n"><a href="#t37">37</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t38" class="pln"><span class="n"><a href="#t38">38</a></span><span class="t"><span class="str">    fit_intercept : bool</span>&nbsp;</span><span class="r"></span></p>
    <p id="t39" class="pln"><span class="n"><a href="#t39">39</a></span><span class="t"><span class="str">        Specifies if a constant (a.k.a. bias or intercept) will be</span>&nbsp;</span><span class="r"></span></p>
    <p id="t40" class="pln"><span class="n"><a href="#t40">40</a></span><span class="t"><span class="str">        added to the decision function.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t41" class="pln"><span class="n"><a href="#t41">41</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t42" class="pln"><span class="n"><a href="#t42">42</a></span><span class="t"><span class="str">    n_samples : int, optional</span>&nbsp;</span><span class="r"></span></p>
    <p id="t43" class="pln"><span class="n"><a href="#t43">43</a></span><span class="t"><span class="str">        Number of rows in X. Useful if is_saga=True.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t44" class="pln"><span class="n"><a href="#t44">44</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t45" class="pln"><span class="n"><a href="#t45">45</a></span><span class="t"><span class="str">    is_saga : boolean, optional</span>&nbsp;</span><span class="r"></span></p>
    <p id="t46" class="pln"><span class="n"><a href="#t46">46</a></span><span class="t"><span class="str">        Whether to return step size for the SAGA algorithm or the SAG</span>&nbsp;</span><span class="r"></span></p>
    <p id="t47" class="pln"><span class="n"><a href="#t47">47</a></span><span class="t"><span class="str">        algorithm.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t48" class="pln"><span class="n"><a href="#t48">48</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t49" class="pln"><span class="n"><a href="#t49">49</a></span><span class="t"><span class="str">    Returns</span>&nbsp;</span><span class="r"></span></p>
    <p id="t50" class="pln"><span class="n"><a href="#t50">50</a></span><span class="t"><span class="str">    -------</span>&nbsp;</span><span class="r"></span></p>
    <p id="t51" class="pln"><span class="n"><a href="#t51">51</a></span><span class="t"><span class="str">    step_size : float</span>&nbsp;</span><span class="r"></span></p>
    <p id="t52" class="pln"><span class="n"><a href="#t52">52</a></span><span class="t"><span class="str">        Step size used in SAG solver.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t53" class="pln"><span class="n"><a href="#t53">53</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t54" class="pln"><span class="n"><a href="#t54">54</a></span><span class="t"><span class="str">    References</span>&nbsp;</span><span class="r"></span></p>
    <p id="t55" class="pln"><span class="n"><a href="#t55">55</a></span><span class="t"><span class="str">    ----------</span>&nbsp;</span><span class="r"></span></p>
    <p id="t56" class="pln"><span class="n"><a href="#t56">56</a></span><span class="t"><span class="str">    Schmidt, M., Roux, N. L., &amp; Bach, F. (2013).</span>&nbsp;</span><span class="r"></span></p>
    <p id="t57" class="pln"><span class="n"><a href="#t57">57</a></span><span class="t"><span class="str">    Minimizing finite sums with the stochastic average gradient</span>&nbsp;</span><span class="r"></span></p>
    <p id="t58" class="pln"><span class="n"><a href="#t58">58</a></span><span class="t"><span class="str">    https://hal.inria.fr/hal-00860051/document</span>&nbsp;</span><span class="r"></span></p>
    <p id="t59" class="pln"><span class="n"><a href="#t59">59</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t60" class="pln"><span class="n"><a href="#t60">60</a></span><span class="t"><span class="str">    Defazio, A., Bach F. &amp; Lacoste-Julien S. (2014).</span>&nbsp;</span><span class="r"></span></p>
    <p id="t61" class="pln"><span class="n"><a href="#t61">61</a></span><span class="t"><span class="str">    SAGA: A Fast Incremental Gradient Method With Support</span>&nbsp;</span><span class="r"></span></p>
    <p id="t62" class="pln"><span class="n"><a href="#t62">62</a></span><span class="t"><span class="str">    for Non-Strongly Convex Composite Objectives</span>&nbsp;</span><span class="r"></span></p>
    <p id="t63" class="pln"><span class="n"><a href="#t63">63</a></span><span class="t"><span class="str">    https://arxiv.org/abs/1407.0202</span>&nbsp;</span><span class="r"></span></p>
    <p id="t64" class="pln"><span class="n"><a href="#t64">64</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t65" class="mis show_mis"><span class="n"><a href="#t65">65</a></span><span class="t">    <span class="key">if</span> <span class="nam">loss</span> <span class="key">in</span> <span class="op">(</span><span class="str">'log'</span><span class="op">,</span> <span class="str">'multinomial'</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t66" class="mis show_mis"><span class="n"><a href="#t66">66</a></span><span class="t">        <span class="nam">L</span> <span class="op">=</span> <span class="op">(</span><span class="num">0.25</span> <span class="op">*</span> <span class="op">(</span><span class="nam">max_squared_sum</span> <span class="op">+</span> <span class="nam">int</span><span class="op">(</span><span class="nam">fit_intercept</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="nam">alpha_scaled</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t67" class="mis show_mis"><span class="n"><a href="#t67">67</a></span><span class="t">    <span class="key">elif</span> <span class="nam">loss</span> <span class="op">==</span> <span class="str">'squared'</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t68" class="pln"><span class="n"><a href="#t68">68</a></span><span class="t">        <span class="com"># inverse Lipschitz constant for squared loss</span>&nbsp;</span><span class="r"></span></p>
    <p id="t69" class="mis show_mis"><span class="n"><a href="#t69">69</a></span><span class="t">        <span class="nam">L</span> <span class="op">=</span> <span class="nam">max_squared_sum</span> <span class="op">+</span> <span class="nam">int</span><span class="op">(</span><span class="nam">fit_intercept</span><span class="op">)</span> <span class="op">+</span> <span class="nam">alpha_scaled</span>&nbsp;</span><span class="r"></span></p>
    <p id="t70" class="pln"><span class="n"><a href="#t70">70</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t71" class="mis show_mis"><span class="n"><a href="#t71">71</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"Unknown loss function for SAG solver, got %s "</span>&nbsp;</span><span class="r"></span></p>
    <p id="t72" class="pln"><span class="n"><a href="#t72">72</a></span><span class="t">                         <span class="str">"instead of 'log' or 'squared'"</span> <span class="op">%</span> <span class="nam">loss</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t73" class="mis show_mis"><span class="n"><a href="#t73">73</a></span><span class="t">    <span class="key">if</span> <span class="nam">is_saga</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t74" class="pln"><span class="n"><a href="#t74">74</a></span><span class="t">        <span class="com"># SAGA theoretical step size is 1/3L or 1 / (2 * (L + mu n))</span>&nbsp;</span><span class="r"></span></p>
    <p id="t75" class="pln"><span class="n"><a href="#t75">75</a></span><span class="t">        <span class="com"># See Defazio et al. 2014</span>&nbsp;</span><span class="r"></span></p>
    <p id="t76" class="mis show_mis"><span class="n"><a href="#t76">76</a></span><span class="t">        <span class="nam">mun</span> <span class="op">=</span> <span class="nam">min</span><span class="op">(</span><span class="num">2</span> <span class="op">*</span> <span class="nam">n_samples</span> <span class="op">*</span> <span class="nam">alpha_scaled</span><span class="op">,</span> <span class="nam">L</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t77" class="mis show_mis"><span class="n"><a href="#t77">77</a></span><span class="t">        <span class="nam">step</span> <span class="op">=</span> <span class="num">1.</span> <span class="op">/</span> <span class="op">(</span><span class="num">2</span> <span class="op">*</span> <span class="nam">L</span> <span class="op">+</span> <span class="nam">mun</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t78" class="pln"><span class="n"><a href="#t78">78</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t79" class="pln"><span class="n"><a href="#t79">79</a></span><span class="t">        <span class="com"># SAG theoretical step size is 1/16L but it is recommended to use 1 / L</span>&nbsp;</span><span class="r"></span></p>
    <p id="t80" class="pln"><span class="n"><a href="#t80">80</a></span><span class="t">        <span class="com"># see http://www.birs.ca//workshops//2014/14w5003/files/schmidt.pdf,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t81" class="pln"><span class="n"><a href="#t81">81</a></span><span class="t">        <span class="com"># slide 65</span>&nbsp;</span><span class="r"></span></p>
    <p id="t82" class="mis show_mis"><span class="n"><a href="#t82">82</a></span><span class="t">        <span class="nam">step</span> <span class="op">=</span> <span class="num">1.</span> <span class="op">/</span> <span class="nam">L</span>&nbsp;</span><span class="r"></span></p>
    <p id="t83" class="mis show_mis"><span class="n"><a href="#t83">83</a></span><span class="t">    <span class="key">return</span> <span class="nam">step</span>&nbsp;</span><span class="r"></span></p>
    <p id="t84" class="pln"><span class="n"><a href="#t84">84</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t85" class="pln"><span class="n"><a href="#t85">85</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t86" class="run"><span class="n"><a href="#t86">86</a></span><span class="t"><span class="key">def</span> <span class="nam">sag_solver</span><span class="op">(</span><span class="nam">X</span><span class="op">,</span> <span class="nam">y</span><span class="op">,</span> <span class="nam">sample_weight</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">loss</span><span class="op">=</span><span class="str">'log'</span><span class="op">,</span> <span class="nam">alpha</span><span class="op">=</span><span class="num">1.</span><span class="op">,</span> <span class="nam">beta</span><span class="op">=</span><span class="num">0.</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t87" class="pln"><span class="n"><a href="#t87">87</a></span><span class="t">               <span class="nam">max_iter</span><span class="op">=</span><span class="num">1000</span><span class="op">,</span> <span class="nam">tol</span><span class="op">=</span><span class="num">0.001</span><span class="op">,</span> <span class="nam">verbose</span><span class="op">=</span><span class="num">0</span><span class="op">,</span> <span class="nam">random_state</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t88" class="pln"><span class="n"><a href="#t88">88</a></span><span class="t">               <span class="nam">check_input</span><span class="op">=</span><span class="key">True</span><span class="op">,</span> <span class="nam">max_squared_sum</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t89" class="pln"><span class="n"><a href="#t89">89</a></span><span class="t">               <span class="nam">warm_start_mem</span><span class="op">=</span><span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t90" class="pln"><span class="n"><a href="#t90">90</a></span><span class="t">               <span class="nam">is_saga</span><span class="op">=</span><span class="key">False</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t91" class="pln"><span class="n"><a href="#t91">91</a></span><span class="t">    <span class="str">"""SAG solver for Ridge and LogisticRegression</span>&nbsp;</span><span class="r"></span></p>
    <p id="t92" class="pln"><span class="n"><a href="#t92">92</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t93" class="pln"><span class="n"><a href="#t93">93</a></span><span class="t"><span class="str">    SAG stands for Stochastic Average Gradient: the gradient of the loss is</span>&nbsp;</span><span class="r"></span></p>
    <p id="t94" class="pln"><span class="n"><a href="#t94">94</a></span><span class="t"><span class="str">    estimated each sample at a time and the model is updated along the way with</span>&nbsp;</span><span class="r"></span></p>
    <p id="t95" class="pln"><span class="n"><a href="#t95">95</a></span><span class="t"><span class="str">    a constant learning rate.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t96" class="pln"><span class="n"><a href="#t96">96</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t97" class="pln"><span class="n"><a href="#t97">97</a></span><span class="t"><span class="str">    IMPORTANT NOTE: 'sag' solver converges faster on columns that are on the</span>&nbsp;</span><span class="r"></span></p>
    <p id="t98" class="pln"><span class="n"><a href="#t98">98</a></span><span class="t"><span class="str">    same scale. You can normalize the data by using</span>&nbsp;</span><span class="r"></span></p>
    <p id="t99" class="pln"><span class="n"><a href="#t99">99</a></span><span class="t"><span class="str">    sklearn.preprocessing.StandardScaler on your data before passing it to the</span>&nbsp;</span><span class="r"></span></p>
    <p id="t100" class="pln"><span class="n"><a href="#t100">100</a></span><span class="t"><span class="str">    fit method.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t101" class="pln"><span class="n"><a href="#t101">101</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t102" class="pln"><span class="n"><a href="#t102">102</a></span><span class="t"><span class="str">    This implementation works with data represented as dense numpy arrays or</span>&nbsp;</span><span class="r"></span></p>
    <p id="t103" class="pln"><span class="n"><a href="#t103">103</a></span><span class="t"><span class="str">    sparse scipy arrays of floating point values for the features. It will</span>&nbsp;</span><span class="r"></span></p>
    <p id="t104" class="pln"><span class="n"><a href="#t104">104</a></span><span class="t"><span class="str">    fit the data according to squared loss or log loss.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t105" class="pln"><span class="n"><a href="#t105">105</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t106" class="pln"><span class="n"><a href="#t106">106</a></span><span class="t"><span class="str">    The regularizer is a penalty added to the loss function that shrinks model</span>&nbsp;</span><span class="r"></span></p>
    <p id="t107" class="pln"><span class="n"><a href="#t107">107</a></span><span class="t"><span class="str">    parameters towards the zero vector using the squared euclidean norm L2.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t108" class="pln"><span class="n"><a href="#t108">108</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t109" class="pln"><span class="n"><a href="#t109">109</a></span><span class="t"><span class="str">    .. versionadded:: 0.17</span>&nbsp;</span><span class="r"></span></p>
    <p id="t110" class="pln"><span class="n"><a href="#t110">110</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t111" class="pln"><span class="n"><a href="#t111">111</a></span><span class="t"><span class="str">    Parameters</span>&nbsp;</span><span class="r"></span></p>
    <p id="t112" class="pln"><span class="n"><a href="#t112">112</a></span><span class="t"><span class="str">    ----------</span>&nbsp;</span><span class="r"></span></p>
    <p id="t113" class="pln"><span class="n"><a href="#t113">113</a></span><span class="t"><span class="str">    X : {array-like, sparse matrix}, shape (n_samples, n_features)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t114" class="pln"><span class="n"><a href="#t114">114</a></span><span class="t"><span class="str">        Training data</span>&nbsp;</span><span class="r"></span></p>
    <p id="t115" class="pln"><span class="n"><a href="#t115">115</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t116" class="pln"><span class="n"><a href="#t116">116</a></span><span class="t"><span class="str">    y : numpy array, shape (n_samples,)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t117" class="pln"><span class="n"><a href="#t117">117</a></span><span class="t"><span class="str">        Target values. With loss='multinomial', y must be label encoded</span>&nbsp;</span><span class="r"></span></p>
    <p id="t118" class="pln"><span class="n"><a href="#t118">118</a></span><span class="t"><span class="str">        (see preprocessing.LabelEncoder).</span>&nbsp;</span><span class="r"></span></p>
    <p id="t119" class="pln"><span class="n"><a href="#t119">119</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t120" class="pln"><span class="n"><a href="#t120">120</a></span><span class="t"><span class="str">    sample_weight : array-like, shape (n_samples,), optional</span>&nbsp;</span><span class="r"></span></p>
    <p id="t121" class="pln"><span class="n"><a href="#t121">121</a></span><span class="t"><span class="str">        Weights applied to individual samples (1. for unweighted).</span>&nbsp;</span><span class="r"></span></p>
    <p id="t122" class="pln"><span class="n"><a href="#t122">122</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t123" class="pln"><span class="n"><a href="#t123">123</a></span><span class="t"><span class="str">    loss : 'log' | 'squared' | 'multinomial'</span>&nbsp;</span><span class="r"></span></p>
    <p id="t124" class="pln"><span class="n"><a href="#t124">124</a></span><span class="t"><span class="str">        Loss function that will be optimized:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t125" class="pln"><span class="n"><a href="#t125">125</a></span><span class="t"><span class="str">        -'log' is the binary logistic loss, as used in LogisticRegression.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t126" class="pln"><span class="n"><a href="#t126">126</a></span><span class="t"><span class="str">        -'squared' is the squared loss, as used in Ridge.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t127" class="pln"><span class="n"><a href="#t127">127</a></span><span class="t"><span class="str">        -'multinomial' is the multinomial logistic loss, as used in</span>&nbsp;</span><span class="r"></span></p>
    <p id="t128" class="pln"><span class="n"><a href="#t128">128</a></span><span class="t"><span class="str">         LogisticRegression.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t129" class="pln"><span class="n"><a href="#t129">129</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t130" class="pln"><span class="n"><a href="#t130">130</a></span><span class="t"><span class="str">        .. versionadded:: 0.18</span>&nbsp;</span><span class="r"></span></p>
    <p id="t131" class="pln"><span class="n"><a href="#t131">131</a></span><span class="t"><span class="str">           *loss='multinomial'*</span>&nbsp;</span><span class="r"></span></p>
    <p id="t132" class="pln"><span class="n"><a href="#t132">132</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t133" class="pln"><span class="n"><a href="#t133">133</a></span><span class="t"><span class="str">    alpha : float, optional</span>&nbsp;</span><span class="r"></span></p>
    <p id="t134" class="pln"><span class="n"><a href="#t134">134</a></span><span class="t"><span class="str">        L2 regularization term in the objective function</span>&nbsp;</span><span class="r"></span></p>
    <p id="t135" class="pln"><span class="n"><a href="#t135">135</a></span><span class="t"><span class="str">        ``(0.5 * alpha * || W ||_F^2)``. Defaults to 1.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t136" class="pln"><span class="n"><a href="#t136">136</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t137" class="pln"><span class="n"><a href="#t137">137</a></span><span class="t"><span class="str">    beta : float, optional</span>&nbsp;</span><span class="r"></span></p>
    <p id="t138" class="pln"><span class="n"><a href="#t138">138</a></span><span class="t"><span class="str">        L1 regularization term in the objective function</span>&nbsp;</span><span class="r"></span></p>
    <p id="t139" class="pln"><span class="n"><a href="#t139">139</a></span><span class="t"><span class="str">        ``(beta * || W ||_1)``. Only applied if ``is_saga`` is set to True.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t140" class="pln"><span class="n"><a href="#t140">140</a></span><span class="t"><span class="str">        Defaults to 0.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t141" class="pln"><span class="n"><a href="#t141">141</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t142" class="pln"><span class="n"><a href="#t142">142</a></span><span class="t"><span class="str">    max_iter : int, optional</span>&nbsp;</span><span class="r"></span></p>
    <p id="t143" class="pln"><span class="n"><a href="#t143">143</a></span><span class="t"><span class="str">        The max number of passes over the training data if the stopping</span>&nbsp;</span><span class="r"></span></p>
    <p id="t144" class="pln"><span class="n"><a href="#t144">144</a></span><span class="t"><span class="str">        criteria is not reached. Defaults to 1000.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t145" class="pln"><span class="n"><a href="#t145">145</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t146" class="pln"><span class="n"><a href="#t146">146</a></span><span class="t"><span class="str">    tol : double, optional</span>&nbsp;</span><span class="r"></span></p>
    <p id="t147" class="pln"><span class="n"><a href="#t147">147</a></span><span class="t"><span class="str">        The stopping criteria for the weights. The iterations will stop when</span>&nbsp;</span><span class="r"></span></p>
    <p id="t148" class="pln"><span class="n"><a href="#t148">148</a></span><span class="t"><span class="str">        max(change in weights) / max(weights) &lt; tol. Defaults to .001</span>&nbsp;</span><span class="r"></span></p>
    <p id="t149" class="pln"><span class="n"><a href="#t149">149</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t150" class="pln"><span class="n"><a href="#t150">150</a></span><span class="t"><span class="str">    verbose : integer, optional</span>&nbsp;</span><span class="r"></span></p>
    <p id="t151" class="pln"><span class="n"><a href="#t151">151</a></span><span class="t"><span class="str">        The verbosity level.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t152" class="pln"><span class="n"><a href="#t152">152</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t153" class="pln"><span class="n"><a href="#t153">153</a></span><span class="t"><span class="str">    random_state : int, RandomState instance or None, optional, default None</span>&nbsp;</span><span class="r"></span></p>
    <p id="t154" class="pln"><span class="n"><a href="#t154">154</a></span><span class="t"><span class="str">        The seed of the pseudo random number generator to use when shuffling</span>&nbsp;</span><span class="r"></span></p>
    <p id="t155" class="pln"><span class="n"><a href="#t155">155</a></span><span class="t"><span class="str">        the data.  If int, random_state is the seed used by the random number</span>&nbsp;</span><span class="r"></span></p>
    <p id="t156" class="pln"><span class="n"><a href="#t156">156</a></span><span class="t"><span class="str">        generator; If RandomState instance, random_state is the random number</span>&nbsp;</span><span class="r"></span></p>
    <p id="t157" class="pln"><span class="n"><a href="#t157">157</a></span><span class="t"><span class="str">        generator; If None, the random number generator is the RandomState</span>&nbsp;</span><span class="r"></span></p>
    <p id="t158" class="pln"><span class="n"><a href="#t158">158</a></span><span class="t"><span class="str">        instance used by `np.random`.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t159" class="pln"><span class="n"><a href="#t159">159</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t160" class="pln"><span class="n"><a href="#t160">160</a></span><span class="t"><span class="str">    check_input : bool, default True</span>&nbsp;</span><span class="r"></span></p>
    <p id="t161" class="pln"><span class="n"><a href="#t161">161</a></span><span class="t"><span class="str">        If False, the input arrays X and y will not be checked.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t162" class="pln"><span class="n"><a href="#t162">162</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t163" class="pln"><span class="n"><a href="#t163">163</a></span><span class="t"><span class="str">    max_squared_sum : float, default None</span>&nbsp;</span><span class="r"></span></p>
    <p id="t164" class="pln"><span class="n"><a href="#t164">164</a></span><span class="t"><span class="str">        Maximum squared sum of X over samples. If None, it will be computed,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t165" class="pln"><span class="n"><a href="#t165">165</a></span><span class="t"><span class="str">        going through all the samples. The value should be precomputed</span>&nbsp;</span><span class="r"></span></p>
    <p id="t166" class="pln"><span class="n"><a href="#t166">166</a></span><span class="t"><span class="str">        to speed up cross validation.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t167" class="pln"><span class="n"><a href="#t167">167</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t168" class="pln"><span class="n"><a href="#t168">168</a></span><span class="t"><span class="str">    warm_start_mem : dict, optional</span>&nbsp;</span><span class="r"></span></p>
    <p id="t169" class="pln"><span class="n"><a href="#t169">169</a></span><span class="t"><span class="str">        The initialization parameters used for warm starting. Warm starting is</span>&nbsp;</span><span class="r"></span></p>
    <p id="t170" class="pln"><span class="n"><a href="#t170">170</a></span><span class="t"><span class="str">        currently used in LogisticRegression but not in Ridge.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t171" class="pln"><span class="n"><a href="#t171">171</a></span><span class="t"><span class="str">        It contains:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t172" class="pln"><span class="n"><a href="#t172">172</a></span><span class="t"><span class="str">            - 'coef': the weight vector, with the intercept in last line</span>&nbsp;</span><span class="r"></span></p>
    <p id="t173" class="pln"><span class="n"><a href="#t173">173</a></span><span class="t"><span class="str">                if the intercept is fitted.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t174" class="pln"><span class="n"><a href="#t174">174</a></span><span class="t"><span class="str">            - 'gradient_memory': the scalar gradient for all seen samples.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t175" class="pln"><span class="n"><a href="#t175">175</a></span><span class="t"><span class="str">            - 'sum_gradient': the sum of gradient over all seen samples,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t176" class="pln"><span class="n"><a href="#t176">176</a></span><span class="t"><span class="str">                for each feature.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t177" class="pln"><span class="n"><a href="#t177">177</a></span><span class="t"><span class="str">            - 'intercept_sum_gradient': the sum of gradient over all seen</span>&nbsp;</span><span class="r"></span></p>
    <p id="t178" class="pln"><span class="n"><a href="#t178">178</a></span><span class="t"><span class="str">                samples, for the intercept.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t179" class="pln"><span class="n"><a href="#t179">179</a></span><span class="t"><span class="str">            - 'seen': array of boolean describing the seen samples.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t180" class="pln"><span class="n"><a href="#t180">180</a></span><span class="t"><span class="str">            - 'num_seen': the number of seen samples.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t181" class="pln"><span class="n"><a href="#t181">181</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t182" class="pln"><span class="n"><a href="#t182">182</a></span><span class="t"><span class="str">    is_saga : boolean, optional</span>&nbsp;</span><span class="r"></span></p>
    <p id="t183" class="pln"><span class="n"><a href="#t183">183</a></span><span class="t"><span class="str">        Whether to use the SAGA algorithm or the SAG algorithm. SAGA behaves</span>&nbsp;</span><span class="r"></span></p>
    <p id="t184" class="pln"><span class="n"><a href="#t184">184</a></span><span class="t"><span class="str">        better in the first epochs, and allow for l1 regularisation.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t185" class="pln"><span class="n"><a href="#t185">185</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t186" class="pln"><span class="n"><a href="#t186">186</a></span><span class="t"><span class="str">    Returns</span>&nbsp;</span><span class="r"></span></p>
    <p id="t187" class="pln"><span class="n"><a href="#t187">187</a></span><span class="t"><span class="str">    -------</span>&nbsp;</span><span class="r"></span></p>
    <p id="t188" class="pln"><span class="n"><a href="#t188">188</a></span><span class="t"><span class="str">    coef_ : array, shape (n_features)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t189" class="pln"><span class="n"><a href="#t189">189</a></span><span class="t"><span class="str">        Weight vector.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t190" class="pln"><span class="n"><a href="#t190">190</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t191" class="pln"><span class="n"><a href="#t191">191</a></span><span class="t"><span class="str">    n_iter_ : int</span>&nbsp;</span><span class="r"></span></p>
    <p id="t192" class="pln"><span class="n"><a href="#t192">192</a></span><span class="t"><span class="str">        The number of full pass on all samples.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t193" class="pln"><span class="n"><a href="#t193">193</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t194" class="pln"><span class="n"><a href="#t194">194</a></span><span class="t"><span class="str">    warm_start_mem : dict</span>&nbsp;</span><span class="r"></span></p>
    <p id="t195" class="pln"><span class="n"><a href="#t195">195</a></span><span class="t"><span class="str">        Contains a 'coef' key with the fitted result, and possibly the</span>&nbsp;</span><span class="r"></span></p>
    <p id="t196" class="pln"><span class="n"><a href="#t196">196</a></span><span class="t"><span class="str">        fitted intercept at the end of the array. Contains also other keys</span>&nbsp;</span><span class="r"></span></p>
    <p id="t197" class="pln"><span class="n"><a href="#t197">197</a></span><span class="t"><span class="str">        used for warm starting.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t198" class="pln"><span class="n"><a href="#t198">198</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t199" class="pln"><span class="n"><a href="#t199">199</a></span><span class="t"><span class="str">    Examples</span>&nbsp;</span><span class="r"></span></p>
    <p id="t200" class="pln"><span class="n"><a href="#t200">200</a></span><span class="t"><span class="str">    --------</span>&nbsp;</span><span class="r"></span></p>
    <p id="t201" class="pln"><span class="n"><a href="#t201">201</a></span><span class="t"><span class="str">    >>> import numpy as np</span>&nbsp;</span><span class="r"></span></p>
    <p id="t202" class="pln"><span class="n"><a href="#t202">202</a></span><span class="t"><span class="str">    >>> from sklearn import linear_model</span>&nbsp;</span><span class="r"></span></p>
    <p id="t203" class="pln"><span class="n"><a href="#t203">203</a></span><span class="t"><span class="str">    >>> n_samples, n_features = 10, 5</span>&nbsp;</span><span class="r"></span></p>
    <p id="t204" class="pln"><span class="n"><a href="#t204">204</a></span><span class="t"><span class="str">    >>> rng = np.random.RandomState(0)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t205" class="pln"><span class="n"><a href="#t205">205</a></span><span class="t"><span class="str">    >>> X = rng.randn(n_samples, n_features)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t206" class="pln"><span class="n"><a href="#t206">206</a></span><span class="t"><span class="str">    >>> y = rng.randn(n_samples)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t207" class="pln"><span class="n"><a href="#t207">207</a></span><span class="t"><span class="str">    >>> clf = linear_model.Ridge(solver='sag')</span>&nbsp;</span><span class="r"></span></p>
    <p id="t208" class="pln"><span class="n"><a href="#t208">208</a></span><span class="t"><span class="str">    >>> clf.fit(X, y)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t209" class="pln"><span class="n"><a href="#t209">209</a></span><span class="t"><span class="str">    ... #doctest: +NORMALIZE_WHITESPACE</span>&nbsp;</span><span class="r"></span></p>
    <p id="t210" class="pln"><span class="n"><a href="#t210">210</a></span><span class="t"><span class="str">    Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t211" class="pln"><span class="n"><a href="#t211">211</a></span><span class="t"><span class="str">          normalize=False, random_state=None, solver='sag', tol=0.001)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t212" class="pln"><span class="n"><a href="#t212">212</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t213" class="pln"><span class="n"><a href="#t213">213</a></span><span class="t"><span class="str">    >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])</span>&nbsp;</span><span class="r"></span></p>
    <p id="t214" class="pln"><span class="n"><a href="#t214">214</a></span><span class="t"><span class="str">    >>> y = np.array([1, 1, 2, 2])</span>&nbsp;</span><span class="r"></span></p>
    <p id="t215" class="pln"><span class="n"><a href="#t215">215</a></span><span class="t"><span class="str">    >>> clf = linear_model.LogisticRegression(</span>&nbsp;</span><span class="r"></span></p>
    <p id="t216" class="pln"><span class="n"><a href="#t216">216</a></span><span class="t"><span class="str">    ...     solver='sag', multi_class='multinomial')</span>&nbsp;</span><span class="r"></span></p>
    <p id="t217" class="pln"><span class="n"><a href="#t217">217</a></span><span class="t"><span class="str">    >>> clf.fit(X, y)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t218" class="pln"><span class="n"><a href="#t218">218</a></span><span class="t"><span class="str">    ... #doctest: +NORMALIZE_WHITESPACE</span>&nbsp;</span><span class="r"></span></p>
    <p id="t219" class="pln"><span class="n"><a href="#t219">219</a></span><span class="t"><span class="str">    LogisticRegression(C=1.0, class_weight=None, dual=False,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t220" class="pln"><span class="n"><a href="#t220">220</a></span><span class="t"><span class="str">        fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t221" class="pln"><span class="n"><a href="#t221">221</a></span><span class="t"><span class="str">        multi_class='multinomial', n_jobs=None, penalty='l2',</span>&nbsp;</span><span class="r"></span></p>
    <p id="t222" class="pln"><span class="n"><a href="#t222">222</a></span><span class="t"><span class="str">        random_state=None, solver='sag', tol=0.0001, verbose=0,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t223" class="pln"><span class="n"><a href="#t223">223</a></span><span class="t"><span class="str">        warm_start=False)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t224" class="pln"><span class="n"><a href="#t224">224</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t225" class="pln"><span class="n"><a href="#t225">225</a></span><span class="t"><span class="str">    References</span>&nbsp;</span><span class="r"></span></p>
    <p id="t226" class="pln"><span class="n"><a href="#t226">226</a></span><span class="t"><span class="str">    ----------</span>&nbsp;</span><span class="r"></span></p>
    <p id="t227" class="pln"><span class="n"><a href="#t227">227</a></span><span class="t"><span class="str">    Schmidt, M., Roux, N. L., &amp; Bach, F. (2013).</span>&nbsp;</span><span class="r"></span></p>
    <p id="t228" class="pln"><span class="n"><a href="#t228">228</a></span><span class="t"><span class="str">    Minimizing finite sums with the stochastic average gradient</span>&nbsp;</span><span class="r"></span></p>
    <p id="t229" class="pln"><span class="n"><a href="#t229">229</a></span><span class="t"><span class="str">    https://hal.inria.fr/hal-00860051/document</span>&nbsp;</span><span class="r"></span></p>
    <p id="t230" class="pln"><span class="n"><a href="#t230">230</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t231" class="pln"><span class="n"><a href="#t231">231</a></span><span class="t"><span class="str">    Defazio, A., Bach F. &amp; Lacoste-Julien S. (2014).</span>&nbsp;</span><span class="r"></span></p>
    <p id="t232" class="pln"><span class="n"><a href="#t232">232</a></span><span class="t"><span class="str">    SAGA: A Fast Incremental Gradient Method With Support</span>&nbsp;</span><span class="r"></span></p>
    <p id="t233" class="pln"><span class="n"><a href="#t233">233</a></span><span class="t"><span class="str">    for Non-Strongly Convex Composite Objectives</span>&nbsp;</span><span class="r"></span></p>
    <p id="t234" class="pln"><span class="n"><a href="#t234">234</a></span><span class="t"><span class="str">    https://arxiv.org/abs/1407.0202</span>&nbsp;</span><span class="r"></span></p>
    <p id="t235" class="pln"><span class="n"><a href="#t235">235</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t236" class="pln"><span class="n"><a href="#t236">236</a></span><span class="t"><span class="str">    See also</span>&nbsp;</span><span class="r"></span></p>
    <p id="t237" class="pln"><span class="n"><a href="#t237">237</a></span><span class="t"><span class="str">    --------</span>&nbsp;</span><span class="r"></span></p>
    <p id="t238" class="pln"><span class="n"><a href="#t238">238</a></span><span class="t"><span class="str">    Ridge, SGDRegressor, ElasticNet, Lasso, SVR, and</span>&nbsp;</span><span class="r"></span></p>
    <p id="t239" class="pln"><span class="n"><a href="#t239">239</a></span><span class="t"><span class="str">    LogisticRegression, SGDClassifier, LinearSVC, Perceptron</span>&nbsp;</span><span class="r"></span></p>
    <p id="t240" class="pln"><span class="n"><a href="#t240">240</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p id="t241" class="mis show_mis"><span class="n"><a href="#t241">241</a></span><span class="t">    <span class="key">if</span> <span class="nam">warm_start_mem</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t242" class="mis show_mis"><span class="n"><a href="#t242">242</a></span><span class="t">        <span class="nam">warm_start_mem</span> <span class="op">=</span> <span class="op">{</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p id="t243" class="pln"><span class="n"><a href="#t243">243</a></span><span class="t">    <span class="com"># Ridge default max_iter is None</span>&nbsp;</span><span class="r"></span></p>
    <p id="t244" class="mis show_mis"><span class="n"><a href="#t244">244</a></span><span class="t">    <span class="key">if</span> <span class="nam">max_iter</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t245" class="mis show_mis"><span class="n"><a href="#t245">245</a></span><span class="t">        <span class="nam">max_iter</span> <span class="op">=</span> <span class="num">1000</span>&nbsp;</span><span class="r"></span></p>
    <p id="t246" class="pln"><span class="n"><a href="#t246">246</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t247" class="mis show_mis"><span class="n"><a href="#t247">247</a></span><span class="t">    <span class="key">if</span> <span class="nam">check_input</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t248" class="mis show_mis"><span class="n"><a href="#t248">248</a></span><span class="t">        <span class="nam">_dtype</span> <span class="op">=</span> <span class="op">[</span><span class="nam">np</span><span class="op">.</span><span class="nam">float64</span><span class="op">,</span> <span class="nam">np</span><span class="op">.</span><span class="nam">float32</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p id="t249" class="mis show_mis"><span class="n"><a href="#t249">249</a></span><span class="t">        <span class="nam">X</span> <span class="op">=</span> <span class="nam">check_array</span><span class="op">(</span><span class="nam">X</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="nam">_dtype</span><span class="op">,</span> <span class="nam">accept_sparse</span><span class="op">=</span><span class="str">'csr'</span><span class="op">,</span> <span class="nam">order</span><span class="op">=</span><span class="str">'C'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t250" class="mis show_mis"><span class="n"><a href="#t250">250</a></span><span class="t">        <span class="nam">y</span> <span class="op">=</span> <span class="nam">check_array</span><span class="op">(</span><span class="nam">y</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="nam">_dtype</span><span class="op">,</span> <span class="nam">ensure_2d</span><span class="op">=</span><span class="key">False</span><span class="op">,</span> <span class="nam">order</span><span class="op">=</span><span class="str">'C'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t251" class="pln"><span class="n"><a href="#t251">251</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t252" class="mis show_mis"><span class="n"><a href="#t252">252</a></span><span class="t">    <span class="nam">n_samples</span><span class="op">,</span> <span class="nam">n_features</span> <span class="op">=</span> <span class="nam">X</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span> <span class="nam">X</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p id="t253" class="pln"><span class="n"><a href="#t253">253</a></span><span class="t">    <span class="com"># As in SGD, the alpha is scaled by n_samples.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t254" class="mis show_mis"><span class="n"><a href="#t254">254</a></span><span class="t">    <span class="nam">alpha_scaled</span> <span class="op">=</span> <span class="nam">float</span><span class="op">(</span><span class="nam">alpha</span><span class="op">)</span> <span class="op">/</span> <span class="nam">n_samples</span>&nbsp;</span><span class="r"></span></p>
    <p id="t255" class="mis show_mis"><span class="n"><a href="#t255">255</a></span><span class="t">    <span class="nam">beta_scaled</span> <span class="op">=</span> <span class="nam">float</span><span class="op">(</span><span class="nam">beta</span><span class="op">)</span> <span class="op">/</span> <span class="nam">n_samples</span>&nbsp;</span><span class="r"></span></p>
    <p id="t256" class="pln"><span class="n"><a href="#t256">256</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t257" class="pln"><span class="n"><a href="#t257">257</a></span><span class="t">    <span class="com"># if loss == 'multinomial', y should be label encoded.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t258" class="mis show_mis"><span class="n"><a href="#t258">258</a></span><span class="t">    <span class="nam">n_classes</span> <span class="op">=</span> <span class="nam">int</span><span class="op">(</span><span class="nam">y</span><span class="op">.</span><span class="nam">max</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="num">1</span> <span class="key">if</span> <span class="nam">loss</span> <span class="op">==</span> <span class="str">'multinomial'</span> <span class="key">else</span> <span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p id="t259" class="pln"><span class="n"><a href="#t259">259</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t260" class="pln"><span class="n"><a href="#t260">260</a></span><span class="t">    <span class="com"># initialization</span>&nbsp;</span><span class="r"></span></p>
    <p id="t261" class="mis show_mis"><span class="n"><a href="#t261">261</a></span><span class="t">    <span class="key">if</span> <span class="nam">sample_weight</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t262" class="mis show_mis"><span class="n"><a href="#t262">262</a></span><span class="t">        <span class="nam">sample_weight</span> <span class="op">=</span> <span class="nam">np</span><span class="op">.</span><span class="nam">ones</span><span class="op">(</span><span class="nam">n_samples</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="nam">X</span><span class="op">.</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">order</span><span class="op">=</span><span class="str">'C'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t263" class="pln"><span class="n"><a href="#t263">263</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t264" class="mis show_mis"><span class="n"><a href="#t264">264</a></span><span class="t">    <span class="key">if</span> <span class="str">'coef'</span> <span class="key">in</span> <span class="nam">warm_start_mem</span><span class="op">.</span><span class="nam">keys</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t265" class="mis show_mis"><span class="n"><a href="#t265">265</a></span><span class="t">        <span class="nam">coef_init</span> <span class="op">=</span> <span class="nam">warm_start_mem</span><span class="op">[</span><span class="str">'coef'</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p id="t266" class="pln"><span class="n"><a href="#t266">266</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t267" class="pln"><span class="n"><a href="#t267">267</a></span><span class="t">        <span class="com"># assume fit_intercept is False</span>&nbsp;</span><span class="r"></span></p>
    <p id="t268" class="mis show_mis"><span class="n"><a href="#t268">268</a></span><span class="t">        <span class="nam">coef_init</span> <span class="op">=</span> <span class="nam">np</span><span class="op">.</span><span class="nam">zeros</span><span class="op">(</span><span class="op">(</span><span class="nam">n_features</span><span class="op">,</span> <span class="nam">n_classes</span><span class="op">)</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="nam">X</span><span class="op">.</span><span class="nam">dtype</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t269" class="pln"><span class="n"><a href="#t269">269</a></span><span class="t">                             <span class="nam">order</span><span class="op">=</span><span class="str">'C'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t270" class="pln"><span class="n"><a href="#t270">270</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t271" class="pln"><span class="n"><a href="#t271">271</a></span><span class="t">    <span class="com"># coef_init contains possibly the intercept_init at the end.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t272" class="pln"><span class="n"><a href="#t272">272</a></span><span class="t">    <span class="com"># Note that Ridge centers the data before fitting, so fit_intercept=False.</span>&nbsp;</span><span class="r"></span></p>
    <p id="t273" class="mis show_mis"><span class="n"><a href="#t273">273</a></span><span class="t">    <span class="nam">fit_intercept</span> <span class="op">=</span> <span class="nam">coef_init</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">==</span> <span class="op">(</span><span class="nam">n_features</span> <span class="op">+</span> <span class="num">1</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t274" class="mis show_mis"><span class="n"><a href="#t274">274</a></span><span class="t">    <span class="key">if</span> <span class="nam">fit_intercept</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t275" class="mis show_mis"><span class="n"><a href="#t275">275</a></span><span class="t">        <span class="nam">intercept_init</span> <span class="op">=</span> <span class="nam">coef_init</span><span class="op">[</span><span class="op">-</span><span class="num">1</span><span class="op">,</span> <span class="op">:</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p id="t276" class="mis show_mis"><span class="n"><a href="#t276">276</a></span><span class="t">        <span class="nam">coef_init</span> <span class="op">=</span> <span class="nam">coef_init</span><span class="op">[</span><span class="op">:</span><span class="op">-</span><span class="num">1</span><span class="op">,</span> <span class="op">:</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p id="t277" class="pln"><span class="n"><a href="#t277">277</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t278" class="mis show_mis"><span class="n"><a href="#t278">278</a></span><span class="t">        <span class="nam">intercept_init</span> <span class="op">=</span> <span class="nam">np</span><span class="op">.</span><span class="nam">zeros</span><span class="op">(</span><span class="nam">n_classes</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="nam">X</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t279" class="pln"><span class="n"><a href="#t279">279</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t280" class="mis show_mis"><span class="n"><a href="#t280">280</a></span><span class="t">    <span class="key">if</span> <span class="str">'intercept_sum_gradient'</span> <span class="key">in</span> <span class="nam">warm_start_mem</span><span class="op">.</span><span class="nam">keys</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t281" class="mis show_mis"><span class="n"><a href="#t281">281</a></span><span class="t">        <span class="nam">intercept_sum_gradient</span> <span class="op">=</span> <span class="nam">warm_start_mem</span><span class="op">[</span><span class="str">'intercept_sum_gradient'</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p id="t282" class="pln"><span class="n"><a href="#t282">282</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t283" class="mis show_mis"><span class="n"><a href="#t283">283</a></span><span class="t">        <span class="nam">intercept_sum_gradient</span> <span class="op">=</span> <span class="nam">np</span><span class="op">.</span><span class="nam">zeros</span><span class="op">(</span><span class="nam">n_classes</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="nam">X</span><span class="op">.</span><span class="nam">dtype</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t284" class="pln"><span class="n"><a href="#t284">284</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t285" class="mis show_mis"><span class="n"><a href="#t285">285</a></span><span class="t">    <span class="key">if</span> <span class="str">'gradient_memory'</span> <span class="key">in</span> <span class="nam">warm_start_mem</span><span class="op">.</span><span class="nam">keys</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t286" class="mis show_mis"><span class="n"><a href="#t286">286</a></span><span class="t">        <span class="nam">gradient_memory_init</span> <span class="op">=</span> <span class="nam">warm_start_mem</span><span class="op">[</span><span class="str">'gradient_memory'</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p id="t287" class="pln"><span class="n"><a href="#t287">287</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t288" class="mis show_mis"><span class="n"><a href="#t288">288</a></span><span class="t">        <span class="nam">gradient_memory_init</span> <span class="op">=</span> <span class="nam">np</span><span class="op">.</span><span class="nam">zeros</span><span class="op">(</span><span class="op">(</span><span class="nam">n_samples</span><span class="op">,</span> <span class="nam">n_classes</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t289" class="pln"><span class="n"><a href="#t289">289</a></span><span class="t">                                        <span class="nam">dtype</span><span class="op">=</span><span class="nam">X</span><span class="op">.</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">order</span><span class="op">=</span><span class="str">'C'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t290" class="mis show_mis"><span class="n"><a href="#t290">290</a></span><span class="t">    <span class="key">if</span> <span class="str">'sum_gradient'</span> <span class="key">in</span> <span class="nam">warm_start_mem</span><span class="op">.</span><span class="nam">keys</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t291" class="mis show_mis"><span class="n"><a href="#t291">291</a></span><span class="t">        <span class="nam">sum_gradient_init</span> <span class="op">=</span> <span class="nam">warm_start_mem</span><span class="op">[</span><span class="str">'sum_gradient'</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p id="t292" class="pln"><span class="n"><a href="#t292">292</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t293" class="mis show_mis"><span class="n"><a href="#t293">293</a></span><span class="t">        <span class="nam">sum_gradient_init</span> <span class="op">=</span> <span class="nam">np</span><span class="op">.</span><span class="nam">zeros</span><span class="op">(</span><span class="op">(</span><span class="nam">n_features</span><span class="op">,</span> <span class="nam">n_classes</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t294" class="pln"><span class="n"><a href="#t294">294</a></span><span class="t">                                     <span class="nam">dtype</span><span class="op">=</span><span class="nam">X</span><span class="op">.</span><span class="nam">dtype</span><span class="op">,</span> <span class="nam">order</span><span class="op">=</span><span class="str">'C'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t295" class="pln"><span class="n"><a href="#t295">295</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t296" class="mis show_mis"><span class="n"><a href="#t296">296</a></span><span class="t">    <span class="key">if</span> <span class="str">'seen'</span> <span class="key">in</span> <span class="nam">warm_start_mem</span><span class="op">.</span><span class="nam">keys</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t297" class="mis show_mis"><span class="n"><a href="#t297">297</a></span><span class="t">        <span class="nam">seen_init</span> <span class="op">=</span> <span class="nam">warm_start_mem</span><span class="op">[</span><span class="str">'seen'</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p id="t298" class="pln"><span class="n"><a href="#t298">298</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t299" class="mis show_mis"><span class="n"><a href="#t299">299</a></span><span class="t">        <span class="nam">seen_init</span> <span class="op">=</span> <span class="nam">np</span><span class="op">.</span><span class="nam">zeros</span><span class="op">(</span><span class="nam">n_samples</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="nam">np</span><span class="op">.</span><span class="nam">int32</span><span class="op">,</span> <span class="nam">order</span><span class="op">=</span><span class="str">'C'</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t300" class="pln"><span class="n"><a href="#t300">300</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t301" class="mis show_mis"><span class="n"><a href="#t301">301</a></span><span class="t">    <span class="key">if</span> <span class="str">'num_seen'</span> <span class="key">in</span> <span class="nam">warm_start_mem</span><span class="op">.</span><span class="nam">keys</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t302" class="mis show_mis"><span class="n"><a href="#t302">302</a></span><span class="t">        <span class="nam">num_seen_init</span> <span class="op">=</span> <span class="nam">warm_start_mem</span><span class="op">[</span><span class="str">'num_seen'</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p id="t303" class="pln"><span class="n"><a href="#t303">303</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t304" class="mis show_mis"><span class="n"><a href="#t304">304</a></span><span class="t">        <span class="nam">num_seen_init</span> <span class="op">=</span> <span class="num">0</span>&nbsp;</span><span class="r"></span></p>
    <p id="t305" class="pln"><span class="n"><a href="#t305">305</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t306" class="mis show_mis"><span class="n"><a href="#t306">306</a></span><span class="t">    <span class="nam">dataset</span><span class="op">,</span> <span class="nam">intercept_decay</span> <span class="op">=</span> <span class="nam">make_dataset</span><span class="op">(</span><span class="nam">X</span><span class="op">,</span> <span class="nam">y</span><span class="op">,</span> <span class="nam">sample_weight</span><span class="op">,</span> <span class="nam">random_state</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t307" class="pln"><span class="n"><a href="#t307">307</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t308" class="mis show_mis"><span class="n"><a href="#t308">308</a></span><span class="t">    <span class="key">if</span> <span class="nam">max_squared_sum</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t309" class="mis show_mis"><span class="n"><a href="#t309">309</a></span><span class="t">        <span class="nam">max_squared_sum</span> <span class="op">=</span> <span class="nam">row_norms</span><span class="op">(</span><span class="nam">X</span><span class="op">,</span> <span class="nam">squared</span><span class="op">=</span><span class="key">True</span><span class="op">)</span><span class="op">.</span><span class="nam">max</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t310" class="mis show_mis"><span class="n"><a href="#t310">310</a></span><span class="t">    <span class="nam">step_size</span> <span class="op">=</span> <span class="nam">get_auto_step_size</span><span class="op">(</span><span class="nam">max_squared_sum</span><span class="op">,</span> <span class="nam">alpha_scaled</span><span class="op">,</span> <span class="nam">loss</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t311" class="pln"><span class="n"><a href="#t311">311</a></span><span class="t">                                   <span class="nam">fit_intercept</span><span class="op">,</span> <span class="nam">n_samples</span><span class="op">=</span><span class="nam">n_samples</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t312" class="pln"><span class="n"><a href="#t312">312</a></span><span class="t">                                   <span class="nam">is_saga</span><span class="op">=</span><span class="nam">is_saga</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t313" class="mis show_mis"><span class="n"><a href="#t313">313</a></span><span class="t">    <span class="key">if</span> <span class="nam">step_size</span> <span class="op">*</span> <span class="nam">alpha_scaled</span> <span class="op">==</span> <span class="num">1</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t314" class="mis show_mis"><span class="n"><a href="#t314">314</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ZeroDivisionError</span><span class="op">(</span><span class="str">"Current sag implementation does not handle "</span>&nbsp;</span><span class="r"></span></p>
    <p id="t315" class="pln"><span class="n"><a href="#t315">315</a></span><span class="t">                                <span class="str">"the case step_size * alpha_scaled == 1"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t316" class="pln"><span class="n"><a href="#t316">316</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t317" class="mis show_mis"><span class="n"><a href="#t317">317</a></span><span class="t">    <span class="nam">sag</span> <span class="op">=</span> <span class="nam">sag64</span> <span class="key">if</span> <span class="nam">X</span><span class="op">.</span><span class="nam">dtype</span> <span class="op">==</span> <span class="nam">np</span><span class="op">.</span><span class="nam">float64</span> <span class="key">else</span> <span class="nam">sag32</span>&nbsp;</span><span class="r"></span></p>
    <p id="t318" class="mis show_mis"><span class="n"><a href="#t318">318</a></span><span class="t">    <span class="nam">num_seen</span><span class="op">,</span> <span class="nam">n_iter_</span> <span class="op">=</span> <span class="nam">sag</span><span class="op">(</span><span class="nam">dataset</span><span class="op">,</span> <span class="nam">coef_init</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t319" class="pln"><span class="n"><a href="#t319">319</a></span><span class="t">                            <span class="nam">intercept_init</span><span class="op">,</span> <span class="nam">n_samples</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t320" class="pln"><span class="n"><a href="#t320">320</a></span><span class="t">                            <span class="nam">n_features</span><span class="op">,</span> <span class="nam">n_classes</span><span class="op">,</span> <span class="nam">tol</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t321" class="pln"><span class="n"><a href="#t321">321</a></span><span class="t">                            <span class="nam">max_iter</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t322" class="pln"><span class="n"><a href="#t322">322</a></span><span class="t">                            <span class="nam">loss</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t323" class="pln"><span class="n"><a href="#t323">323</a></span><span class="t">                            <span class="nam">step_size</span><span class="op">,</span> <span class="nam">alpha_scaled</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t324" class="pln"><span class="n"><a href="#t324">324</a></span><span class="t">                            <span class="nam">beta_scaled</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t325" class="pln"><span class="n"><a href="#t325">325</a></span><span class="t">                            <span class="nam">sum_gradient_init</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t326" class="pln"><span class="n"><a href="#t326">326</a></span><span class="t">                            <span class="nam">gradient_memory_init</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t327" class="pln"><span class="n"><a href="#t327">327</a></span><span class="t">                            <span class="nam">seen_init</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t328" class="pln"><span class="n"><a href="#t328">328</a></span><span class="t">                            <span class="nam">num_seen_init</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t329" class="pln"><span class="n"><a href="#t329">329</a></span><span class="t">                            <span class="nam">fit_intercept</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t330" class="pln"><span class="n"><a href="#t330">330</a></span><span class="t">                            <span class="nam">intercept_sum_gradient</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t331" class="pln"><span class="n"><a href="#t331">331</a></span><span class="t">                            <span class="nam">intercept_decay</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t332" class="pln"><span class="n"><a href="#t332">332</a></span><span class="t">                            <span class="nam">is_saga</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t333" class="pln"><span class="n"><a href="#t333">333</a></span><span class="t">                            <span class="nam">verbose</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t334" class="pln"><span class="n"><a href="#t334">334</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t335" class="mis show_mis"><span class="n"><a href="#t335">335</a></span><span class="t">    <span class="key">if</span> <span class="nam">n_iter_</span> <span class="op">==</span> <span class="nam">max_iter</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t336" class="mis show_mis"><span class="n"><a href="#t336">336</a></span><span class="t">        <span class="nam">warnings</span><span class="op">.</span><span class="nam">warn</span><span class="op">(</span><span class="str">"The max_iter was reached which means "</span>&nbsp;</span><span class="r"></span></p>
    <p id="t337" class="pln"><span class="n"><a href="#t337">337</a></span><span class="t">                      <span class="str">"the coef_ did not converge"</span><span class="op">,</span> <span class="nam">ConvergenceWarning</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t338" class="pln"><span class="n"><a href="#t338">338</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t339" class="mis show_mis"><span class="n"><a href="#t339">339</a></span><span class="t">    <span class="key">if</span> <span class="nam">fit_intercept</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t340" class="mis show_mis"><span class="n"><a href="#t340">340</a></span><span class="t">        <span class="nam">coef_init</span> <span class="op">=</span> <span class="nam">np</span><span class="op">.</span><span class="nam">vstack</span><span class="op">(</span><span class="op">(</span><span class="nam">coef_init</span><span class="op">,</span> <span class="nam">intercept_init</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p id="t341" class="pln"><span class="n"><a href="#t341">341</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t342" class="mis show_mis"><span class="n"><a href="#t342">342</a></span><span class="t">    <span class="nam">warm_start_mem</span> <span class="op">=</span> <span class="op">{</span><span class="str">'coef'</span><span class="op">:</span> <span class="nam">coef_init</span><span class="op">,</span> <span class="str">'sum_gradient'</span><span class="op">:</span> <span class="nam">sum_gradient_init</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t343" class="pln"><span class="n"><a href="#t343">343</a></span><span class="t">                      <span class="str">'intercept_sum_gradient'</span><span class="op">:</span> <span class="nam">intercept_sum_gradient</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t344" class="pln"><span class="n"><a href="#t344">344</a></span><span class="t">                      <span class="str">'gradient_memory'</span><span class="op">:</span> <span class="nam">gradient_memory_init</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p id="t345" class="pln"><span class="n"><a href="#t345">345</a></span><span class="t">                      <span class="str">'seen'</span><span class="op">:</span> <span class="nam">seen_init</span><span class="op">,</span> <span class="str">'num_seen'</span><span class="op">:</span> <span class="nam">num_seen</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p id="t346" class="pln"><span class="n"><a href="#t346">346</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t347" class="mis show_mis"><span class="n"><a href="#t347">347</a></span><span class="t">    <span class="key">if</span> <span class="nam">loss</span> <span class="op">==</span> <span class="str">'multinomial'</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t348" class="mis show_mis"><span class="n"><a href="#t348">348</a></span><span class="t">        <span class="nam">coef_</span> <span class="op">=</span> <span class="nam">coef_init</span><span class="op">.</span><span class="nam">T</span>&nbsp;</span><span class="r"></span></p>
    <p id="t349" class="pln"><span class="n"><a href="#t349">349</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p id="t350" class="mis show_mis"><span class="n"><a href="#t350">350</a></span><span class="t">        <span class="nam">coef_</span> <span class="op">=</span> <span class="nam">coef_init</span><span class="op">[</span><span class="op">:</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p id="t351" class="pln"><span class="n"><a href="#t351">351</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p id="t352" class="mis show_mis"><span class="n"><a href="#t352">352</a></span><span class="t">    <span class="key">return</span> <span class="nam">coef_</span><span class="op">,</span> <span class="nam">n_iter_</span><span class="op">,</span> <span class="nam">warm_start_mem</span>&nbsp;</span><span class="r"></span></p>
</div>
<div id="footer">
    <div class="content">
        <p>
            <a class="nav" href="index.html">&#xab; index</a> &nbsp; &nbsp; <a class="nav" href="https://coverage.readthedocs.io">coverage.py v5.0.3</a>,
            created at 2020-01-27 12:54
        </p>
    </div>
</div>
</body>
</html>
